{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m segmented_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/Cipleu/Documents/IULIA/SCOALA/facultate/Year 4 Semester 1/PRS/Lab/Project/charactersResulted\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[0;32m     35\u001b[0m images_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/Cipleu/Documents/IULIA/SCOALA/facultate/Year 4 Semester 1/PRS/Lab/Project/dataset/imagesForTesting/plates\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[1;32m---> 37\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegmented_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Split the dataset into training and testing sets\u001b[39;00m\n\u001b[0;32m     40\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 21\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(images_folder, segmented_folder)\u001b[0m\n\u001b[0;32m     18\u001b[0m char_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(char_img_path, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Get the corresponding label (the first character in the name of the license plate image)\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[43mlicense_plate_name\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchar_img_name\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Get the correct character (e.g., B, 8, J, etc.)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Append the character image and label to the lists\u001b[39;00m\n\u001b[0;32m     24\u001b[0m X\u001b[38;5;241m.\u001b[39mappend(char_image)\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "def load_data(images_folder, segmented_folder):\n",
    "    X = []  # Image data (character images)\n",
    "    y = []  # Corresponding labels (characters)\n",
    "\n",
    "    # Loop through each image in the images folder\n",
    "    for license_plate_image in os.listdir(images_folder):\n",
    "        if license_plate_image.endswith('.png'):\n",
    "            license_plate_name = license_plate_image.split('.')[0]  \n",
    "            # Path to the folder containing segmented characters for this license plate\n",
    "            segmented_path = os.path.join(segmented_folder, license_plate_name)\n",
    "\n",
    "            # Loop through the segmented characters in the corresponding folder\n",
    "            for char_img_name in os.listdir(segmented_path):\n",
    "                if char_img_name.endswith('.png'):\n",
    "                    # Load character image\n",
    "                    char_img_path = os.path.join(segmented_path, char_img_name)\n",
    "                    char_image = cv2.imread(char_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    \n",
    "                    # Get the corresponding label (the first character in the name of the license plate image)\n",
    "                    label = license_plate_name[int(char_img_name.split('.')[0])]  \n",
    "\n",
    "                    # Append the character image and label to the lists\n",
    "                    X.append(char_image)\n",
    "                    y.append(label)\n",
    "\n",
    "    # Convert lists to numpy arrays for easier manipulation\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Example usage:\n",
    "segmented_folder = \"C:/Users/Cipleu/Documents/IULIA/SCOALA/facultate/Year 4 Semester 1/PRS/Lab/Project/charactersResulted\"  \n",
    "images_folder = \"C:/Users/Cipleu/Documents/IULIA/SCOALA/facultate/Year 4 Semester 1/PRS/Lab/Project/dataset/imagesForTesting/plates\"  \n",
    "\n",
    "X, y = load_data(images_folder, segmented_folder)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of Oriented Gradients (HOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized Image Shape: (64, 128)\n",
      "Gradient Magnitude Shape: (64, 128)\n",
      "Gradient Angle Shape: (64, 128)\n",
      "Number of Cells: 128\n",
      "Block Histograms Length: 240\n",
      "Computed HOG Features: [[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.96251843e-01 2.41667948e-02 3.70202273e-03 1.46697018e-03\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.41396242e-01 0.00000000e+00 7.23251167e-05 2.15038031e-04\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.41396242e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [2.39342597e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.42561894e-01 3.82588024e-03 7.19970459e-04 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.41396242e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [2.39342597e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.42561894e-01 3.82588024e-03 7.19970459e-04 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [5.70740038e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  5.17625607e-02 9.23763978e-02 1.49882038e-02 1.56787023e-02\n",
      "  1.36601406e-02]\n",
      " [1.24376324e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  6.23006053e-03 1.34252169e-02 5.88726056e-03 3.71072256e-03\n",
      "  1.79312060e-02]\n",
      " [5.70740038e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  5.17625607e-02 9.23763978e-02 1.49882038e-02 1.56787023e-02\n",
      "  1.36601406e-02]\n",
      " [1.24376324e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  6.23006053e-03 1.34252169e-02 5.88726056e-03 3.71072256e-03\n",
      "  1.79312060e-02]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class HOGDescriptor:\n",
    "    def __init__(self, cell_size=(8, 8), block_size=(2, 2), nbins=9):\n",
    "        self.cell_size = cell_size\n",
    "        self.block_size = block_size\n",
    "        self.nbins = nbins\n",
    "\n",
    "    def compute_gradients(self, image):\n",
    "        # Compute gradients along x and y directions\n",
    "        gx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        gy = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        \n",
    "        # Compute magnitude and angle\n",
    "        magnitude = np.sqrt(gx**2 + gy**2)\n",
    "        angle = np.arctan2(gy, gx) * (180 / np.pi) % 180  # Angle in degrees between 0 and 180\n",
    "        \n",
    "        return magnitude, angle\n",
    "\n",
    "    def compute_histograms(self, magnitude, angle):\n",
    "        # Divide the image into cells and compute histograms\n",
    "        cell_histograms = []\n",
    "        for i in range(0, magnitude.shape[0], self.cell_size[0]):\n",
    "            for j in range(0, magnitude.shape[1], self.cell_size[1]):\n",
    "                cell_magnitude = magnitude[i:i + self.cell_size[0], j:j + self.cell_size[1]]\n",
    "                cell_angle = angle[i:i + self.cell_size[0], j:j + self.cell_size[1]]\n",
    "                \n",
    "                # Compute histogram for each cell\n",
    "                hist = np.zeros(self.nbins)\n",
    "                for m, a in zip(cell_magnitude.flatten(), cell_angle.flatten()):\n",
    "                    bin_idx = int(a // (180 / self.nbins))  # Bin index\n",
    "                    hist[bin_idx] += m  # Add magnitude to corresponding bin\n",
    "                \n",
    "                cell_histograms.append(hist)\n",
    "        return np.array(cell_histograms)\n",
    "\n",
    "    def compute(self, image):\n",
    "        # Resize image\n",
    "        image_resized = cv2.resize(image, (128, 64))\n",
    "        print(f\"Resized Image Shape: {image_resized.shape}\")\n",
    "        \n",
    "        # Compute gradients and histogram of gradients\n",
    "        magnitude, angle = self.compute_gradients(image_resized)\n",
    "        print(f\"Gradient Magnitude Shape: {magnitude.shape}\")\n",
    "        print(f\"Gradient Angle Shape: {angle.shape}\")\n",
    "        \n",
    "        # Compute histograms for cells\n",
    "        cell_histograms = self.compute_histograms(magnitude, angle)\n",
    "        print(f\"Number of Cells: {len(cell_histograms)}\")\n",
    "        \n",
    "        # Group cells into blocks and normalize histograms\n",
    "        block_histograms = []\n",
    "        for i in range(0, len(cell_histograms) - (self.block_size[0] - 1) * 8, self.block_size[1]):\n",
    "            block = cell_histograms[i:i + self.block_size[0] * self.block_size[1]]\n",
    "            block_histograms.extend(block)\n",
    "        \n",
    "        # L2-norm normalization\n",
    "        block_histograms = np.array(block_histograms)\n",
    "        block_histograms /= np.sqrt(np.sum(block_histograms**2) + 1e-6)\n",
    "        \n",
    "        print(f\"Block Histograms Length: {len(block_histograms)}\")\n",
    "        return block_histograms\n",
    "\n",
    "# Example usage:\n",
    "image = cv2.imread('C:/Users/Cipleu/Documents/IULIA/SCOALA/facultate/Year 4 Semester 1/PRS/Lab/Project/charactersResulted/YWORRY/0.png', cv2.IMREAD_GRAYSCALE)  # Load grayscale image\n",
    "hog = HOGDescriptor()\n",
    "features = hog.compute(image)\n",
    "\n",
    "# Print some of the computed features (optional)\n",
    "print(f\"Computed HOG Features: {features[:10]}\")  # Print the first 10 HOG features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayesian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_probs = defaultdict(float)  # Class probabilities\n",
    "        self.feature_probs = defaultdict(lambda: defaultdict(float))  # Feature probabilities given class\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Train Naive Bayes classifier.\n",
    "        \n",
    "        :param X_train: List of feature vectors\n",
    "        :param y_train: List of class labels\n",
    "        \"\"\"\n",
    "        n_samples = len(X_train)\n",
    "        class_counts = defaultdict(int)\n",
    "        \n",
    "        # Count occurrences of each class\n",
    "        for label in y_train:\n",
    "            class_counts[label] += 1\n",
    "        print(\"Class counts:\", class_counts)\n",
    "        \n",
    "        # Calculate class probabilities\n",
    "        for label, count in class_counts.items():\n",
    "            self.class_probs[label] = count / n_samples\n",
    "        print(\"Class probabilities:\", self.class_probs)\n",
    "        \n",
    "        # Calculate feature probabilities given each class\n",
    "        feature_counts = defaultdict(lambda: defaultdict(int))\n",
    "        for i in range(n_samples):\n",
    "            label = y_train[i]\n",
    "            features = X_train[i]\n",
    "            for feature in features:\n",
    "                feature_counts[label][feature] += 1\n",
    "\n",
    "        for label, features in feature_counts.items():\n",
    "            total_features = sum(features.values())\n",
    "            print(f\"Total features for class {label}: {total_features}\")\n",
    "            for feature, count in features.items():\n",
    "                self.feature_probs[label][feature] = count / total_features\n",
    "                print(f\"Feature probabilities for class {label}, feature {feature}: {self.feature_probs[label][feature]}\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Predict class labels for the given test data.\n",
    "        \n",
    "        :param X_test: List of feature vectors to classify\n",
    "        :return: List of predicted class labels\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        for features in X_test:\n",
    "            class_scores = {}\n",
    "            print(f\"\\nPredicting for features: {features}\")\n",
    "            for label, class_prob in self.class_probs.items():\n",
    "                score = np.log(class_prob)\n",
    "                print(f\"Class {label} initial score (log prior): {score}\")\n",
    "                for feature in features:\n",
    "                    feature_prob = self.feature_probs[label].get(feature, 1e-5)  # Apply Laplace smoothing\n",
    "                    score += np.log(feature_prob)\n",
    "                    print(f\"Feature {feature} score for class {label}: {np.log(feature_prob)}\")\n",
    "                class_scores[label] = score\n",
    "                print(f\"Total score for class {label}: {score}\")\n",
    "            predicted_class = max(class_scores, key=class_scores.get)\n",
    "            print(f\"Predicted class: {predicted_class}\")\n",
    "            predictions.append(predicted_class)\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voting Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "VotingClassifier.__init__() got an unexpected keyword argument 'estimators'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 31\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m     26\u001b[0m classifiers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     27\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnaive_bayes\u001b[39m\u001b[38;5;124m'\u001b[39m, NaiveBayesClassifier()),\n\u001b[0;32m     28\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_forest\u001b[39m\u001b[38;5;124m'\u001b[39m, RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m))\n\u001b[0;32m     29\u001b[0m ]\n\u001b[1;32m---> 31\u001b[0m voting_clf \u001b[38;5;241m=\u001b[39m \u001b[43mVotingClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassifiers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhard\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Use 'hard' voting for majority class\u001b[39;00m\n\u001b[0;32m     32\u001b[0m voting_clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Predict using the voting classifier\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: VotingClassifier.__init__() got an unexpected keyword argument 'estimators'"
     ]
    }
   ],
   "source": [
    "class VotingClassifier:\n",
    "    def __init__(self, classifiers, weights=None):\n",
    "        self.classifiers = classifiers\n",
    "        self.weights = weights if weights else [1] * len(classifiers)\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        for clf in self.classifiers:\n",
    "            clf.train(X_train, y_train)  # Train each classifier\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # Get predictions from all classifiers\n",
    "        all_preds = []\n",
    "        for clf in self.classifiers:\n",
    "            all_preds.append(clf.predict(X_test))\n",
    "        \n",
    "        # Perform weighted voting\n",
    "        weighted_preds = np.zeros(len(X_test))\n",
    "        for i, preds in enumerate(zip(*all_preds)):\n",
    "            scores = np.zeros(len(set(preds)))  # Assuming class labels are integers\n",
    "            for j, pred in enumerate(preds):\n",
    "                scores[pred] += self.weights[i]\n",
    "            weighted_preds[i] = np.argmax(scores)  # Choose class with max score\n",
    "        return weighted_preds\n",
    "\n",
    "# Example usage:\n",
    "classifiers = [\n",
    "    ('naive_bayes', NaiveBayesClassifier()),\n",
    "    ('random_forest', RandomForestClassifier(n_estimators=100))\n",
    "]\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=classifiers, voting='hard')  # Use 'hard' voting for majority class\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the voting classifier\n",
    "predictions = voting_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
